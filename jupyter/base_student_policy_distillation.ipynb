{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f08c2-bc63-4471-a547-f911af3fd006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class RolloutDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.samples = []\n",
    "        filepaths = glob.glob(os.path.join(data_dir, '*.pt'))\n",
    "        # print(filepaths)\n",
    "        for filepath in tqdm(filepaths, desc=\"Loading rollouts\", unit=\"file\"):\n",
    "            try:\n",
    "                print(filepath)\n",
    "                rollout = torch.load(filepath)\n",
    "                if len(rollout) < 100:\n",
    "                    continue\n",
    "            except RuntimeError:\n",
    "                tqdm.write(f\"Skipping unreadable file {os.path.basename(filepath)}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"rollout length: {len(rollout)}\")\n",
    "            for step in rollout:\n",
    "                obs = step['obs'].flatten()\n",
    "                act = step['act'].flatten()\n",
    "                \n",
    "                if torch.isnan(obs).any() or torch.isinf(obs).any() \\\n",
    "                or torch.isnan(act).any() or torch.isinf(act).any():\n",
    "                    continue\n",
    "                    \n",
    "                if act.abs().max().item() > 10:\n",
    "                    continue\n",
    "\n",
    "                self.samples.append((obs, act))\n",
    "                \n",
    "        self.length = len(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "    \n",
    "def kl_divergence_fixed_std(mean_s, mean_t, std_t):\n",
    "    var = std_t.pow(2)\n",
    "    return ((mean_s - mean_t).pow(2) / (2*var)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0cbf12-42e5-4c90-a609-4eaa1b5b9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_export(dataset,\n",
    "                     teacher_std_np,\n",
    "                     epochs=50,\n",
    "                     batch_size=128,\n",
    "                     lr=3e-4,\n",
    "                     in_dim=None,\n",
    "                     base_model_name=\"models/tqw_student_policy_base_jit_275.pt\",\n",
    "                     device=None,\n",
    "                     output_dir='models'):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    policy = torch.jit.load(base_model_name)\n",
    "    # policy = policy.to(dtype=torch.double)\n",
    "        \n",
    "    policy.eval() \n",
    "\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=lr)\n",
    "    # teacher_std = torch.tensor(teacher_std_np, device=device).unsqueeze(0).double()\n",
    "    teacher_std = torch.tensor(teacher_std_np, device=device).unsqueeze(0)\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        policy.train()\n",
    "        total_loss = 0.0\n",
    "        for obs_batch, act_batch in loader:\n",
    "            obs_batch = obs_batch.to(device=device)\n",
    "            act_batch = act_batch.to(device=device)\n",
    "            # obs_batch = (obs_batch - obs_mean) / obs_std\n",
    "            optimizer.zero_grad()\n",
    "            mean_s = policy(obs_batch)\n",
    "            loss = kl_divergence_fixed_std(mean_s, act_batch, teacher_std)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * obs_batch.size(0)\n",
    "\n",
    "        print(f\"Epoch {ep}/{epochs}, Loss: {total_loss/len(dataset):.6f}\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    torch.save(policy.state_dict(), os.path.join(output_dir, 'distilled_policy_test.pth'))\n",
    "    print(\"Saved distilled_policy.pth\")\n",
    "    \n",
    "    example_input = torch.randn(1, in_dim).to(device)\n",
    "    traced = torch.jit.trace(policy, example_input)\n",
    "    \n",
    "    traced.save(os.path.join(output_dir, 'distilled_policy.pt'))\n",
    "    print(\"Saved JIT policy with normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae0ea16-7706-41d2-99c5-9765bf5ab96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wheeled_data_dir='/root/workspace/personal/akamisaka/quadruped_wheelchairs/D2/datasets/wheeled_mode_dynamics'\n",
    "walking_data_dir='/root/workspace/personal/akamisaka/quadruped_wheelchairs/D2/datasets/walking_mode_dynamics'\n",
    "\n",
    "walking_dataset = RolloutDataset(walking_data_dir)\n",
    "wheeled_dataset = RolloutDataset(wheeled_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59615f7-0c98-42bc-bc0c-0bf108b59a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"num of walking_dataset: {len(walking_dataset)}\")\n",
    "print(f\"num of wheeled_dataset: {len(wheeled_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b235e09-be42-4d08-9795-fe80f1cb265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = wheeled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a6914-715c-4a89-8658-70bf1a833947",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_std_np = np.array([\n",
    "    1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n",
    "])\n",
    "train_and_export(\n",
    "    dataset=dataset,\n",
    "    teacher_std_np=teacher_std_np,\n",
    "    epochs=500,\n",
    "    batch_size=1024,\n",
    "    lr=3e-4,\n",
    "    in_dim=275,\n",
    "    device=None,\n",
    "    output_dir='models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18fae7-b8f6-4b9f-b3bd-5c2134fc4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def check_rollout_file(filepath):\n",
    "    try:\n",
    "        rollout = torch.load(filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 読み込み失敗: {os.path.basename(filepath)} → {e}\")\n",
    "        return\n",
    "\n",
    "    obs_list = []\n",
    "    act_list = []\n",
    "    for step in rollout:\n",
    "        obs_list.append(step['obs'].flatten())\n",
    "        act_list.append(step['act'].flatten())\n",
    "    obs = torch.stack(obs_list, dim=0)\n",
    "    act = torch.stack(act_list, dim=0)\n",
    "\n",
    "    nan_obs  = torch.isnan(obs).any().item()\n",
    "    inf_obs  = torch.isinf(obs).any().item()\n",
    "    nan_act  = torch.isnan(act).any().item()\n",
    "    inf_act  = torch.isinf(act).any().item()\n",
    "\n",
    "    if nan_obs or inf_obs or nan_act or inf_act:\n",
    "        print(f\"[BAD]  {os.path.basename(filepath)}:\", end=\" \")\n",
    "        tags = []\n",
    "        if nan_obs: tags.append(\"NaN in obs\")\n",
    "        if inf_obs: tags.append(\"Inf in obs\")\n",
    "        if nan_act: tags.append(\"NaN in act\")\n",
    "        if inf_act: tags.append(\"Inf in act\")\n",
    "        print(\", \".join(tags))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for path in glob.glob(os.path.join(wheeled_data_dir, \"*.pt\")):\n",
    "        check_rollout_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b644d-b067-484e-9727-255861c667b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutDataset(Dataset):\n",
    "    def __init__(self, data_dir, onehot):\n",
    "        if not torch.is_tensor(onehot):\n",
    "            self.onehot = torch.tensor(onehot, dtype=torch.float32)\n",
    "        else:\n",
    "            self.onehot = onehot.to(dtype=torch.float32)\n",
    "\n",
    "        self.samples = []\n",
    "        filepaths = glob.glob(os.path.join(data_dir, '*.pt'))\n",
    "        for filepath in tqdm(filepaths, desc=\"Loading rollouts\", unit=\"file\"):\n",
    "            try:\n",
    "                rollout = torch.load(filepath)\n",
    "                if len(rollout) < 100:\n",
    "                    continue\n",
    "            except RuntimeError:\n",
    "                tqdm.write(f\"Skipping unreadable file {os.path.basename(filepath)}\")\n",
    "                continue\n",
    "\n",
    "            for step in rollout:\n",
    "                obs = step['obs'].flatten()\n",
    "                obs = torch.cat([obs, self.onehot], dim=0)\n",
    "\n",
    "                act = step['act'].flatten()\n",
    "                \n",
    "                if torch.isnan(obs).any() or torch.isinf(obs).any() \\\n",
    "                or torch.isnan(act).any() or torch.isinf(act).any():\n",
    "                    continue\n",
    "                    \n",
    "                if act.abs().max().item() > 10:\n",
    "                    continue\n",
    "                \n",
    "                self.samples.append((obs, act))\n",
    "\n",
    "        self.length = len(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140c3e1-6857-4978-9679-71b7b2e6962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wheeled_data_dir='/root/workspace/personal/akamisaka/quadruped_wheelchairs/D2/datasets/wheeled_mode_dynamics'\n",
    "walking_data_dir='/root/workspace/personal/akamisaka/quadruped_wheelchairs/D2/datasets/walking_mode_dynamics'\n",
    "\n",
    "walking_dataset = RolloutDataset(walking_data_dir, [0, 1])\n",
    "wheeled_dataset = RolloutDataset(wheeled_data_dir, [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88175360-49d3-4d3e-8508-4d83db9600c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"num of walking_dataset: {len(walking_dataset)}\")\n",
    "print(f\"num of wheeled_dataset: {len(wheeled_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f5bf7-5ae6-473a-9c0e-292c51948a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = walking_dataset[:1400000] + wheeled_dataset[:1400000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd5a84-beea-422e-abf7-3486563543a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_std_np = np.array([\n",
    "    1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n",
    "])\n",
    "train_and_export(\n",
    "    dataset=dataset,\n",
    "    teacher_std_np=teacher_std_np,\n",
    "    epochs=5000,\n",
    "    batch_size=10000,\n",
    "    lr=3e-4,\n",
    "    in_dim=277,\n",
    "    base_model_name=\"models/tqw_student_policy_base_jit_277.pt\",\n",
    "    device=None,\n",
    "    output_dir='models'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
